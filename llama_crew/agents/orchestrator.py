
# https://github.com/run-llama/llama_index/blob/767de070b231fb328b6c0640c2e002c9c7af0a83/docs/docs/examples/agent/custom_agent.ipynb#L12

from typing import List
from llama_index.core.bridge.pydantic import Field, BaseModel
from llama_index.core.output_parsers import PydanticOutputParser

from typing import Dict, Any, Tuple, Optional
from datetime import datetime
import json

class Task(BaseModel):
    input: str
    context: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None
    
class Step(BaseModel):
    agent: str
    subtask: str
    
class Plan(BaseModel):
    goal: str
    steps: List[Step]
class Orchestrator:
    system_prompt = (
        "DATE: {todays_date}\n\n"
        "You are the orchestrator. At your disposal, you have the following list of agents: {agents_list}\nThink step by step.\n"
        "Your job is to decompose the user's task into simple steps, each to be executed by a specific agent that you can choose from the agents list.\n"
        "Once you have the responses from the agents, you need to combine them into a coherent final answer to solve the task.\n\n"
        "TASK: {task}\n\n"
        )
    
    def __init__(self, llm, agents, **kwargs):
        self.llm = llm
        self.agents = agents #{agent["name"]: agent for agent in agents}
        self.agents_config = kwargs.get("agents_config", {})
        self.verbose = kwargs.get("verbose", False)
        self.require_approval = kwargs.get("require_approval", False)
        
    def generate_plan(self, prompt, task):
        response_format = PydanticOutputParser(Plan)
        response = self.llm.complete(prompt + response_format.format_string)
        steps = json.loads(str(response))["steps"]
        # Validation check
        if not steps:
            raise ValueError("Generated plan is empty")
        plan = Plan(goal=task, steps=steps)
        return plan
    
    def approve_plan(self, plan):
        prompt = (
            "Given the following task from the user: {task}\n"
            "And the following plan generated by the orchestrator: {steps}\n"
            "Please approve the plan.\n"
            "ANSWER: (Y)es/(N)o\n"
        )
        response = ""
        while response.lower() not in ["y", "n"]:
            response = input(prompt.format(task=plan.goal, steps=plan.steps))
        if response.lower() == "y":
            return "y", None
        else:
            reason = input("Please provide a reason for disapproving the plan: ")
            return "n", reason
        
    def query(self, task):
        now = datetime.now()
        agent_list = [(agent["name"], agent["role"]) for agent in self.agents_config["agents"]]
        prompt = self.system_prompt.format(agents_list=agent_list,task=task, todays_date=now.strftime("%Y-%m-%d"))
        plan = self.generate_plan(prompt, task)
        
        if self.require_approval:
            approval, reason = self.approve_plan(plan)
            while approval == "n":
                pending_approval_prompt = prompt + f"\n\nFAILED LOGIC: {plan.steps}\n\n REASON: {reason}\n\n"
                plan = self.generate_plan(pending_approval_prompt, task)
                approval, reason = self.approve_plan(plan)
        
        
        if self.verbose:
            print(f"Received the following task: {task}")
            print("Steps:")
            for step in plan.steps:
                print(f"\t{step.agent}: {step.subtask}")
        responses = []
        for step in plan.steps:
            agent_prompt = (
                "Given the User's task: {task}\n"
                "And the following query from the orchestrator: {query}\n"
                "Please provide a response to the query."
            )
            if self.verbose:    
                print(f"Calling agent {step.agent} with the query: {step.subtask}")
            response = self.query_agent(step.agent, agent_prompt.format(task=plan.goal, query=step.subtask))
            if self.verbose:
                print(f"Agent {step.agent} responded with: {response}")
            responses.append(response)
            if (self.can_stop(task, responses)):
                break
        combined_responses = " ".join(str(responses))
        combined_response = self.combine_responses(task, combined_responses)
        eval_response = self.eval_response(task, "orchestrator", task, combined_response)
        if self.verbose:
            print(f"Response evaluation: {eval_response}")
        return combined_response, eval_response
    
    def can_stop(self, task, responses):
        # Generic logic to determine if the orchestrator can stop querying agents based on the responses so far
        prompt = (
            "Given the following task from the user: {task}\n"
            "And the following responses from agents: {responses}\n"
            "Please determine if the orchestrator can stop querying agents.\n"
            "ANSWER: Yes/No"
        )
        response = self.llm.complete(prompt.format(task=task, responses=responses))
        if "Yes" in str(response):
            return True
        return False
    
    def combine_responses(self, original_query, responses):
        # Generic logic to combine responses from different agents based on the original query context
        system_prompt = (
            f"Given the following original query from the user:\n{original_query}\n\n"
            f"And the following responses from agents:\n{responses}\n\n"
            "Please combine these responses into a coherent final answer."
        )
        combined_response = self.llm.complete(system_prompt)
        return combined_response
        
    def eval_response(self, task, agent_name, query, response):
        system_prompt = (
            f"Given the following question from the user:\n{task}\n\n"
            f"The response from {agent_name} to the query {query} is:\n{response}\n\n"
            "Please evaluate the response in the following format: 'has_error: new_question: explanation'"
        )
        return self.llm.complete(system_prompt)
    
    def query_agent(self, agent_name, query):
        return self.agents[agent_name].query(query)

